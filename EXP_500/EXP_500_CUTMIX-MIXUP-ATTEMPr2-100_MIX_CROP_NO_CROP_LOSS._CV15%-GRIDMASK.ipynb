{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFIED LOSS\n",
    "#MIXUP\n",
    "#image with padding 1\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os \n",
    "os.chdir('..')\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.callbacks import TrackerCallback\n",
    "from fastai.callbacks import CSVLogger\n",
    "from fastai.data_block import _maybe_squeeze\n",
    "from fastai.callbacks import *\n",
    "from utils.mxresnet import *\n",
    "from utils.ranger import *\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from joblib import load, dump\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pretrainedmodels\n",
    "\n",
    "\n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MishFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x * torch.tanh(F.softplus(x))   # x * tanh(ln(1 + exp(x)))\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x = ctx.saved_variables[0]\n",
    "        sigmoid = torch.sigmoid(x)\n",
    "        tanh_sp = torch.tanh(F.softplus(x)) \n",
    "        return grad_output * (tanh_sp + x * sigmoid * (1 - tanh_sp * tanh_sp))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return MishFunction.apply(x)\n",
    "\n",
    "def to_Mish(model):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.ReLU):\n",
    "            setattr(model, child_name, Mish())\n",
    "        else:\n",
    "            to_Mish(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 1\n",
    "NAME = 'EXP_500'\n",
    "SUFFIX =f'RESNEX_1CH_MISH_SIMPLE_CUTMIX_CUTOUT_MIXUP_with_CROP_NO_CROP_CV6_FOLD_LOSS_GRIDMASK{FOLD}'\n",
    "PATH = Path('../../../bengaliai')\n",
    "SZ = 128\n",
    "BS = 256\n",
    "NFOLDS = 5 #keep the same split as the initial dataset\n",
    "SEED = 2019\n",
    "TRAIN_IMG = PATH/'img_trn_orig'\n",
    "LABELS = PATH/'train.csv'\n",
    "TRAIN_IMG_CROP = PATH/'img_trn_crop_image'\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "\n",
    "os.chdir(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_strt_split(x, y, n_folds=6, random_seed = 42069, path=Path('')):  \n",
    "    try: \n",
    "        val_name = load('val_idx.joblib')\n",
    "    except:\n",
    "        skf = MultilabelStratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "        val_name = [(val_idx, trn_idx) for trn_idx, val_idx in skf.split(x, y)]\n",
    "        dump(val_name,'val_idx.joblib')\n",
    "    return val_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(str(LABELS))\n",
    "nunique = list(df.nunique())[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = multi_strt_split(df['image_id'], df[df.columns[1:-1]])[FOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "    \n",
    "    Author: Qishen Ha\n",
    "    Email: haqishen@gmail.com\n",
    "    2020/01/29\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "        self.counter = 0\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        self.counter = self.counter \n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(files):\n",
    "    tmp = []\n",
    "    for f in files:\n",
    "        data = pd.read_parquet(f)\n",
    "        tmp.append(data)\n",
    "    tmp = pd.concat(tmp)\n",
    "\n",
    "    data = tmp.iloc[:, 1:].values\n",
    "    return data\n",
    "\n",
    "data_train = read_data([str(PATH/'train_image_data_0.parquet'), \n",
    "                        str(PATH/'train_image_data_1.parquet'), \n",
    "                        str(PATH/'train_image_data_2.parquet'), \n",
    "                        str(PATH/'train_image_data_3.parquet')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fn(fn):\n",
    "    fn = str(fn)\n",
    "    return int(re.findall(r'\\d+', fn)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.OneOf([\n",
    "        GridMask(num_grid=3, mode=0, rotate = 5),\n",
    "        GridMask(num_grid=3, mode=1, rotate = 5),\n",
    "        GridMask(num_grid=3, mode=2, rotate = 5),\n",
    "    ], p=1.0)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8aa0aa1ebf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "class Counter():\n",
    "    def __init__ (self, total_epoch = 100, val_lenth = 167367):\n",
    "        self.counter, self.val_lenth= 0, val_lenth\n",
    "        self.p = 0\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.counter = self.counter + 1\n",
    "        if self.counter%self.val_lenth == 0:\n",
    "            self.p = self.p + 0.01\n",
    "        return min(self.p, 0.8)\n",
    "        \n",
    "  \n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "cn = Counter()\n",
    "def read_data(fn, data = data_train, transform = transforms_train, train_set = val_idx[1]):\n",
    "    fn = get_fn(fn)\n",
    "    img = data[fn].reshape(HEIGHT, WIDTH)\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    #p = cn()\n",
    "    #transform.p = p\n",
    "    \n",
    "    if fn in train_set:\n",
    "        img = transform(image=img)['image']\n",
    "        \n",
    "    img = 255- img.astype(np.uint8)  \n",
    "    img = PIL.Image.fromarray(img).convert('RGB')\n",
    "    x = pil2tensor(img,np.float32)\n",
    "    x.div_(255)\n",
    "    return Image(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "class BenGli(ImageList):\n",
    "    def open(self, fn):\n",
    "        return read_data(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagenet_stats\n",
    "data = (BenGli.from_df(df, path=TRAIN_IMG, folder='', suffix='.png', \n",
    "        cols='image_id', convert_mode='L')\n",
    "        .split_by_idxs(valid_idx=val_idx[0], train_idx=val_idx[1])\n",
    "        .label_from_df(cols=['grapheme_root','vowel_diacritic','consonant_diacritic'])\n",
    "        .transform(tfms=None, size=(SZ, SZ), resize_method=ResizeMethod.SQUISH, padding_mode='zeros')\n",
    "        .databunch(bs=BS)).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, nc, n, ps=0.2):\n",
    "        super().__init__()\n",
    "        layers = [AdaptiveConcatPool2d(), Mish(), Flatten()] + \\\n",
    "            bn_drop_lin(nc*2, 512, True, ps, nn.ReLU(inplace=True)) + \\\n",
    "            bn_drop_lin(512, n, True, ps)\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        self._init_weight()\n",
    "        \n",
    "    def _init_weight(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1.0)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, arch, cut, nc, n=nunique, pre=False, ps=0.5, activ_mish=True):\n",
    "        super().__init__()\n",
    "        self.body=nn.Sequential(*list(arch.children())[:cut])\n",
    "        self.head1 = Head(nc,n[0])\n",
    "        self.head2 = Head(nc,n[1])\n",
    "        self.head3 = Head(nc,n[2])\n",
    "        if activ_mish: \n",
    "            to_Mish(self.head1), to_Mish(self.head2), to_Mish(self.head3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x1 = self.head1(x)\n",
    "        x2 = self.head2(x)\n",
    "        x3 = self.head3(x)\n",
    "        return x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = pretrainedmodels.se_resnext50_32x4d(num_classes=1000)\n",
    "model = CustomHead(arch=arch, cut=-2, nc=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_combine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, input, target,reduction='mean'):\n",
    "        x1,x2,x3 = input\n",
    "        x1,x2,x3 = x1.float(),x2.float(),x3.float()\n",
    "        y = target.long()\n",
    "        return 0.7*F.cross_entropy(x1,y[:,0],reduction=reduction) + 0.1*F.cross_entropy(x2,y[:,1],reduction=reduction) + \\\n",
    "          0.2*F.cross_entropy(x3,y[:,2],reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric_idx(Callback):\n",
    "    def __init__(self, idx, average='macro'):\n",
    "        super().__init__()\n",
    "        self.idx = idx\n",
    "        self.n_classes = 0\n",
    "        self.average = average\n",
    "        self.cm = None\n",
    "        self.eps = 1e-9\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.cm = None\n",
    "    \n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        last_output = last_output[self.idx]\n",
    "        last_target = last_target[:,self.idx]\n",
    "        preds = last_output.argmax(-1).view(-1).cpu()\n",
    "        targs = last_target.long().cpu()\n",
    "        \n",
    "        if self.n_classes == 0:\n",
    "            self.n_classes = last_output.shape[-1]\n",
    "            self.x = torch.arange(0, self.n_classes)\n",
    "        cm = ((preds==self.x[:, None]) & (targs==self.x[:, None, None])) \\\n",
    "          .sum(dim=2, dtype=torch.float32)\n",
    "        if self.cm is None: self.cm =  cm\n",
    "        else:               self.cm += cm\n",
    "\n",
    "    def _weights(self, avg:str):\n",
    "        if self.n_classes != 2 and avg == \"binary\":\n",
    "            avg = self.average = \"macro\"\n",
    "            warn(\"average=`binary` was selected for a non binary case. \\\n",
    "                 Value for average has now been set to `macro` instead.\")\n",
    "        if avg == \"binary\":\n",
    "            if self.pos_label not in (0, 1):\n",
    "                self.pos_label = 1\n",
    "                warn(\"Invalid value for pos_label. It has now been set to 1.\")\n",
    "            if self.pos_label == 1: return Tensor([0,1])\n",
    "            else: return Tensor([1,0])\n",
    "        elif avg == \"micro\": return self.cm.sum(dim=0) / self.cm.sum()\n",
    "        elif avg == \"macro\": return torch.ones((self.n_classes,)) / self.n_classes\n",
    "        elif avg == \"weighted\": return self.cm.sum(dim=1) / self.cm.sum()\n",
    "        \n",
    "    def _recall(self):\n",
    "        rec = torch.diag(self.cm) / (self.cm.sum(dim=1) + self.eps)\n",
    "        if self.average is None: return rec\n",
    "        else:\n",
    "            if self.average == \"micro\": weights = self._weights(avg=\"weighted\")\n",
    "            else: weights = self._weights(avg=self.average)\n",
    "            return (rec * weights).sum()\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs): \n",
    "        return add_metrics(last_metrics, self._recall())\n",
    "    \n",
    "Metric_grapheme = partial(Metric_idx,0)\n",
    "Metric_vowel = partial(Metric_idx,1)\n",
    "Metric_consonant = partial(Metric_idx,2)\n",
    "\n",
    "class Metric_tot(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.grapheme = Metric_idx(0)\n",
    "        self.vowel = Metric_idx(1)\n",
    "        self.consonant = Metric_idx(2)\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.grapheme.on_epoch_begin(**kwargs)\n",
    "        self.vowel.on_epoch_begin(**kwargs)\n",
    "        self.consonant.on_epoch_begin(**kwargs)\n",
    "    \n",
    "    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n",
    "        self.grapheme.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.vowel.on_batch_end(last_output, last_target, **kwargs)\n",
    "        self.consonant.on_batch_end(last_output, last_target, **kwargs)\n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs): \n",
    "        return add_metrics(last_metrics, 0.5*self.grapheme._recall() +\n",
    "                0.25*self.vowel._recall() + 0.25*self.consonant._recall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Learner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3560d68d4b39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Learner.cutmix = cutmix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m learn = Learner(data, model, loss_func=Loss_combine(), opt_func = Over9000, \n\u001b[0m\u001b[1;32m     10\u001b[0m         metrics=[Metric_grapheme(),Metric_vowel(),Metric_consonant(),Metric_tot()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Learner' is not defined"
     ]
    }
   ],
   "source": [
    "#def cutmix(learn:Learner, alpha:float=1.0, stack_x:bool=False, stack_y:bool=True) -> Learner:\n",
    "#    \"Add cutmix https://arxiv.org/pdf/1905.04899.pdf to `learn`.\"\n",
    "#    learn.callback_fns.append(partial(CutMixCallback, alpha=alpha, stack_y=stack_y))\n",
    "#    return learn\n",
    "#\n",
    "#setattr(cutmix, 'cb_fn', CutMixCallback)\n",
    "#Learner.cutmix = cutmix\n",
    "\n",
    "learn = Learner(data, model, loss_func=Loss_combine(), opt_func = Over9000, \n",
    "        metrics=[Metric_grapheme(),Metric_vowel(),Metric_consonant(),Metric_tot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 1e-1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7d9aa53fe6a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f2b259887ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(100, lr, wd=1e-2,  pct_start=0.0,  div_factor=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutdown scheduled for Tue 2020-02-11 15:40:39 UTC, use 'shutdown -c' to cancel.\r\n"
     ]
    }
   ],
   "source": [
    "!sudo shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
